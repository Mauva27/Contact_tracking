{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "os.chdir(\"/Users/jundong/colloids-master/python\")\n",
    "from colloids import track, lif\n",
    "from copy import deepcopy\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import cdist\n",
    "from skimage.filters import threshold_otsu\n",
    "%matplotlib inline\n",
    "\n",
    "import contactAnalysis as ca\n",
    "from contactAnalysis import *\n",
    "import read_lif\n",
    "import _pickle as cPickle\n",
    "# import importlib\n",
    "# importlib.reload(properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['/Users/jundong/PhD_3rd/Experiments/STED/2018_04_13/JD1803_1_11phic0_29Cp0_77_decon/',\n",
    "           '/Users/jundong/PhD_3rd/Experiments/STED/2018_04_14/JD1803_1_11phic0_30Cp1_09/JD1803_1_11phic0_30Cp1_09_Series009_t0_decon/',\n",
    "           '/Users/jundong/PhD_3rd/Experiments/STED/2018_04_14/JD1803_1_11phic0_29Cp1_40_pixel0_127/JD1803_1_11phic0_29Cp1_40_pixel0_127_Series019_decon/',       \n",
    "           '/Users/jundong/PhD_3rd/Experiments/STED/2018_04_12/JD1803_1_11phic0_27Cp1_59_decon_t0/',\n",
    "           '/Users/jundong/PhD_3rd/Experiments/STED/2018_04_05/JD1803-1_11_phic0_30Cp1_83_decon/',\n",
    "           '/Users/jundong/PhD_3rd/Experiments/STED/2018_04_13/JD1803_1_11phic0_29Cp1_88_decon/',\n",
    "           '/Users/jundong/PhD_3rd/Experiments/STED/2018_04_10/JD1803-1_11phic0_26Cp1_89_decon/',\n",
    "           '/Users/jundong/PhD_3rd/Experiments/STED/2018_04_11/JD1803_1_11phic0_37Cp2_18_recheck/JD1803_1_11phic0_37Cp2_18_recheck_t0_decon/']\n",
    "\n",
    "lif_names = [\"JD1803_1_11phic0_29Cp0_77_decon.lif\",\n",
    "             \"JD1803_1_11phic0_30Cp1_09_Series009_t0_decon.lif\",\n",
    "             \"JD1803_1_11phic0_29Cp1_40_pixel0_127_Series019_decon.lif\",\n",
    "             \"JD1803_1_11phic0_27Cp1_59_decon_t0.lif\",\n",
    "             \"JD1803-1_11_phic0_30Cp1_83_decon.lif\",\n",
    "             \"JD1803_1_11phic0_29Cp1_88_decon.lif\",\n",
    "             \"JD1803-1_11phic0_26Cp1_89_decon.lif\",\n",
    "             \"JD1803_1_11phic0_37Cp2_18_recheck_t0_decon.lif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_idx=[0,1,6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:42<00:00,  4.28s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particle diameter 21 neighbour distance 28\n",
      "folder 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.03s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particle diameter 21 neighbour distance 26\n",
      "folder 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particle diameter 21 neighbour distance 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Calculate g(r) to get the distance of the first minimum, to define neighbour distance\n",
    "from tqdm import tqdm\n",
    "from contactAnalysis import g_r\n",
    "t=0\n",
    "for f in folder_idx:\n",
    "    print ('folder',f)\n",
    "    folder = folders[f]\n",
    "    lif_name = lif_names[f]\n",
    "    \n",
    "    gr_resutls = []\n",
    "    for i in tqdm(range(10)):\n",
    "        r,GR,IGR,IG=g_r.gr(folder+'t%01d/c1/particle_center.xyz'%t,1,1,1,screen=False)\n",
    "        p_sigma, maxdistance = g_r.first_minimum(GR)\n",
    "        gr_resutls.append((p_sigma,maxdistance))\n",
    "    np.savetxt(folder+'t%01d/c1/gr_dparticle_dneighbour.txt'%t,max(gr_resutls))\n",
    "    print ('particle diameter',max(gr_resutls)[0],'neighbour distance', max(gr_resutls)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in folder_idx:\n",
    "    print ('folder',f)\n",
    "    t=0\n",
    "\n",
    "    #### load both channel images (C1 and C2) from .lif file\n",
    "    folder = folders[f]  \n",
    "    reader = read_lif.Reader(folder+lif_names[f])\n",
    "    series = reader.getSeries()\n",
    "    image_xyz_c1 = series[0].getFrame(T=t)\n",
    "    image_xyz_c2 = series[1].getFrame(T=t)\n",
    "    \n",
    "    imageC1=np.swapaxes(image_xyz_c1,0,2)      #### z, y, x\n",
    "    imageC2=np.swapaxes(image_xyz_c2,0,2)      #### z, y, x\n",
    "    print ('imageC2 shape is', imageC2.shape)\n",
    "\n",
    "    #### Load coordinates of particles\n",
    "    pcen_all = np.loadtxt(folder+\"t%01d/c1/particle_center.txt\"%t)\n",
    "    print (pcen_all[:,1].max(), pcen_all[:,3].mean())\n",
    "    pcen = deepcopy(pcen_all)\n",
    "    \n",
    "    # index of particles at edges and inside the box\n",
    "    edge_particle, p_inbox = analysis.remove_edge_particles(imageC2,pcen_all)\n",
    "    particle_inbox = pcen_all[p_inbox]\n",
    "\n",
    "    p_cen = particle_inbox\n",
    "    p_rad = particle_inbox[:,3]\n",
    "    \n",
    "    \n",
    "    #### Calculate the distance of the first minimum in g(r)\n",
    "    _gr = np.loadtxt(folder+'t%01d/c1/gr_dparticle_dneighbour.txt'%t)\n",
    "    p_sigma, maxdistance = _gr[0],_gr[1]\n",
    "    print ('particle diameter',p_sigma,'neighbour distance', maxdistance)\n",
    "\n",
    "    \n",
    "     #'###### Calculate volume fraction'\n",
    "    from contactAnalysis import properties, figures\n",
    "    sizeFactor = p_sigma/p_cen[:,3].mean()/2\n",
    "    print (sizeFactor)\n",
    "    phi,pd,z_first,z_last = properties.volume_fraction(p_cen,imageC2,factor=sizeFactor,z_range=True)\n",
    "    print (phi,pd,z_first,z_last)\n",
    "\n",
    "    figures.pd_hist(p_cen[:,3],folder+'t%01d/c1/'%t,bin_number=20)\n",
    "    f = open(folder+'t%01d/c1/phic_pd_t%01d_removeEdges.txt'%(t,t),'w')\n",
    "    f.write('%s %s %s' %('phi_c',phi,'\\n')) \n",
    "    f.write('%s %s %s'%('polydispersity',pd,'\\n'))\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "#     #### Do not consider the empty space in z direction\n",
    "#     density_z = properties.phi_of_z(imageC2,folder,bin_z=30,T=1)\n",
    "#     slices = np.array((int(density_z[1][0]),int(density_z[1][-1])))\n",
    "#     print ('Validate Z slices between',slices)\n",
    "    \n",
    "    \n",
    "    # apply Otsu filter twice to the contacts image\n",
    "    M = imageC2\n",
    "    slices=np.array((z_first, z_last))\n",
    "#     slices = np.array((0,imageC2.shape[0]))\n",
    "    imageC2_part = M[slices[0]:slices[1],:,:]\n",
    "    print (imageC2_part.shape)\n",
    "    background =  threshold_otsu(imageC2_part.ravel())\n",
    "    threshold_contact=threshold_otsu(imageC2_part[imageC2_part>background].ravel())\n",
    "    print ('background threshold', background)\n",
    "    print ('contacts threshold', threshold_contact)\n",
    "    \n",
    "    fig.multifigures_xy3(M,120,200,400)        # Check the images with otsu filter\n",
    "    # threshold images\n",
    "    I2=deepcopy(M)\n",
    "    threshold_C2 = ds.threshold_top_bottom(I2,180, threshold_contact*1.05)\n",
    "    fig.multifigures_xy3(threshold_C2, 120, 200, 400)\n",
    "    plt.savefig(folder+'threhsold.pdf')\n",
    "    \n",
    "    # find middle points between particles\n",
    "    first_minimum = maxdistance\n",
    "    neigbours_distance, n_p = ds.coordination(pcen,maxdistance=first_minimum)[:2]\n",
    "    \n",
    "    # neigbours_distance is a list of \n",
    "    #(particle, its neighbour, distances between these two particles)\n",
    "    # n_p is the number of neighbours\n",
    "    middle_mask,particle_middle = ds.middle_point(pcen,neigbours_distance,imageC2)[:2]\n",
    "    \n",
    "    \n",
    "    mask_thr =0# threshold_contact\n",
    "    spheres, dimmask,struct_size = ds.draw_spheres(middle_mask,imageC2, mask_thr,s_iter=3,dil_iter=1)\n",
    "    labelled_spheres, num_spheres, sphere_size = ds.label_mask(spheres)\n",
    "    print ('number of drawn spheres',num_spheres)\n",
    "    print ('number of middle points',len(particle_middle)/2.)\n",
    "    'The difference is connected spheres'\n",
    "    plt.figure()\n",
    "    plt.hist(sphere_size)\n",
    "    plt.xlabel('Sphere size (pixels)'),plt.ylabel('Counts')\n",
    "    plt.savefig(folder+'t%01d/c2/hist_sphereSizes.pdf'%t)\n",
    "    \n",
    "    labelled_new_mask = labelled_spheres\n",
    "    \n",
    "    \n",
    "    otsu_contacts= ds.force_pdf(I2, labelled_new_mask,threshold_contact)\n",
    "\n",
    "    thr_low = threshold_contact - 10\n",
    "    thr_high = threshold_contact + 10\n",
    "    delta_thr = 4\n",
    "    low_threshold = range(thr_low,thr_high,delta_thr)\n",
    "    histograms = [ds.force_pdf(I2,labelled_new_mask,intensity) for intensity in low_threshold]\n",
    "\n",
    "    for j in range(4):\n",
    "        scaling = ds.force_plot(histograms,otsu_contacts,scaling=j,threshold_range=low_threshold,\n",
    "                                otsu_threshold=threshold_contact,fitting=False)\n",
    "        plt.savefig(folder+\"t%01d/c2/pdf_scaling_test_%s_maskThr%02d.pdf\"%(t,scaling.real,mask_thr))\n",
    "                    \n",
    "    for k in range(len(histograms)):\n",
    "        histogram = np.array(histograms)[k]\n",
    "        fname = folder+'t%01d/c2/histograms/maskThr%02d_force_histograms_%s'%(t,mask_thr,histogram[-1])\n",
    "        ds.write_histogram_file(fname,histogram)\n",
    "\n",
    "    fname = folder+'t%01d/c2/histograms/maskThr%02d_force_histograms_otsu%s'%(t,mask_thr,np.round(otsu_contacts[-1],0))\n",
    "    ds.write_histogram_file(fname,otsu_contacts)\n",
    "                    \n",
    "    coms, maxs,shifted_maxs,contact_size,residualContacts,residualLabels =ds.label_contactCentre(I2,\n",
    "                                                            labelled_new_mask,threshold_contact)[:-1]\n",
    "    ds.contact_centre_save(np.array(coms),contact_size,\n",
    "                           folder+'t%01d/c2/particle_middle/c2enters_Contacts_coms_new_maskThr%02d.txt'%(t,mask_thr))\n",
    "    ds.contact_centre_save(np.array(maxs),contact_size,\n",
    "                           folder+'t%01d/c2/particle_middle/c2enters_Contacts_maxs_new_maskThr%02d.txt'%(t,mask_thr))\n",
    "    ds.contact_centre_save(shifted_maxs,contact_size,\n",
    "                           folder+'t%01d/c2/particle_middle/c2enters_Contacts_shiftedmaxs_new_maskThr%02d.txt'%(t,mask_thr))\n",
    "    \n",
    "\n",
    "    \n",
    "    # Load the coordination of all contacts\n",
    "    contacts= np.loadtxt(folder+'t%01d/c2/particle_middle/c2enters_Contacts_coms_new_maskThr00.txt'%t)\n",
    "    removeLarge = contacts[:,-1]<400        #### !!!!!!\n",
    "    contact_cen_new = contacts[removeLarge][:,:3]\n",
    "    contact_cen = deepcopy(contact_cen_new)\n",
    "    contact_size = contacts[removeLarge][:,-1]\n",
    "    \n",
    "#     mlab.points3d(p_cen[:,0],p_cen[:,1],p_cen[:,2],scale_factor=15,color=(0,0,0))#,p_cen[:,3])\n",
    "#     xc = contact_cen[:,0]\n",
    "#     yc = contact_cen[:,1]\n",
    "#     zc = contact_cen[:,2]\n",
    "#     mlab.points3d(xc,yc,zc, scale_factor=5,color=(0,0,1))\n",
    "#     mlab.show()\n",
    "    \n",
    "#     # compute distances between all contacts and particles\n",
    "    dists=cdist(p_cen[:,:3], contact_cen)\n",
    "    dists.shape\n",
    "\n",
    "    # which two particles have a common contact point\n",
    "    p1_cen, p2_cen, p_tb_connected, connections, forces = analysis.link_particles(\n",
    "                                dists,contact_cen,contact_size,p_cen)\n",
    "\n",
    "    #if a contact is not collinear with two adjacent particles, put three of them collinear\n",
    "    force_vector = analysis.find_force_vector(contact_cen,p1_cen, p2_cen,forces)\n",
    "    # np.savetxt(folder+'t%01d/c2/particle_middle/force_vector.txt'%t ,force_vector)\n",
    "\n",
    "    # calculate number of contacts per particle\n",
    "    # sum of force per particle with magnitude or not\n",
    "    ncontacts,local_sum,local_sum_moduli,order,local_f_list,local_f_sum = analysis.n_contacts_pparticle(\n",
    "                                                    p_tb_connected,force_vector,p_cen)\n",
    "    \n",
    "    coordinations = analysis.coordination(p_cen,maxdistance)\n",
    "    np.savetxt(folder+'t%01d/c2/particle_middle/nContacts.txt'%t,ncontacts)\n",
    "    np.savetxt(folder+'t%01d/c2/particle_middle/nNeighbors.txt'%t,coordinations)\n",
    "    \n",
    "    #### plot p(N) ,P(Z)   \n",
    "    f = plt.figure(figsize=(11,4))\n",
    "    ax1 = f.add_subplot(121)\n",
    "    ax1.hist(ncontacts[ncontacts<13],histtype='step',normed=True)\n",
    "    mean_Z = ncontacts[ncontacts<13].mean()\n",
    "    ax1.text(0.8,0.9,'<$Z$> = %s'%np.round(mean_Z,1), ha='center', va='center', transform=ax1.transAxes,size=12)\n",
    "    ax1.set_xlabel('$Z$'),ax1.set_ylabel('$P(Z)$')\n",
    "    ax1.set_title('Number of contacts, Z')\n",
    "\n",
    "    ax2 = f.add_subplot(122)\n",
    "    ax2.hist(coordinations,histtype='step',normed=True)\n",
    "    mean_N = coordinations.mean()\n",
    "    ax2.text(0.8,0.9,'<$N$> = %s'%np.round(mean_N,1), ha='center', va='center', transform=ax2.transAxes,size=12)\n",
    "    ax2.set_xlabel('$N$'),ax2.set_ylabel('$P(N)$')\n",
    "    ax2.set_title('Number of neighbors, N')\n",
    "\n",
    "    plt.savefig(folder+'t%01d/c2/particle_middle/P(N)_P(Z).pdf'%t)\n",
    "    \n",
    "    #### plot local sum   \n",
    "    f = plt.figure(figsize=(18,4))\n",
    "    ax1 = f.add_subplot(131)\n",
    "    ax1.hist(force_vector[:,-3],bins=30)\n",
    "    ax1.set_xlabel('Force vectors'), ax1.set_ylabel('')\n",
    "    ax1.legend(loc=2)\n",
    "\n",
    "    ax2 = f.add_subplot(132)\n",
    "    ax2.plot(local_sum[order],label='Vector sum of forces')\n",
    "    ax2.plot(local_sum_moduli[order],label = 'Magnitude sum of forces')\n",
    "    ax2.set_xlabel('Droplet Index'), ax2.set_ylabel('')\n",
    "    ax2.legend(loc=2)\n",
    "\n",
    "    # number of contacts distribution along z direction\n",
    "    ax3 = f.add_subplot(133)\n",
    "    bin_num=20\n",
    "    plt.hist(contact_cen[:,2], bins=bin_num,color='g',alpha=0.3,label='Contacts')\n",
    "    plt.xlabel('Z - direction')\n",
    "    plt.ylabel('$Z$')\n",
    "    plt.plot(imageC2.mean(axis=(1,2))*10, lw=2,color='gray', label='Intensity average')\n",
    "    plt.xlim(0,imageC2.shape[0])\n",
    "    plt.legend(loc=1)\n",
    "\n",
    "    plt.savefig(folder+'t%01d/c2/particle_middle/forceSum_NcZ.pdf'%t)\n",
    "    \n",
    "    # compute compression and tension difference\n",
    "    comp_tens_df = analysis.compression_tension(coordinations,ncontacts)\n",
    "    fig.write_xyz_file_p(folder + 't%01d/c2/particle_middle/compression_tension'%t,\n",
    "                                    p_cen,Property =comp_tens_df)\n",
    "    # particles have high contact number, more than 3 contacts\n",
    "    pcen_highcontacts = p_cen[ncontacts>=3]\n",
    "    fig.write_xyz_file(folder + 't%01d/c2/particle_middle/pcen_highcontacts'%t,p_cen)\n",
    "    fig.write_xyz_file_p(folder + 't%01d/c2/particle_middle/particle_num_of_contacts_label'%t,\n",
    "                                    p_cen,Property =ncontacts)\n",
    "    fig.write_xyz_file_p(folder + 't%01d/c2/particle_middle/particle_coordination_label'%t,\n",
    "                                    p_cen,Property =coordinations)\n",
    "\n",
    "    good_ncontacts = ncontacts<13\n",
    "    hists = np.stack((ncontacts[good_ncontacts],coordinations[good_ncontacts]))\n",
    "    # hists = np.stack((ncontacts[pcen_boxmiddle],\n",
    "    #                   coordinations[pcen_boxmiddle]))\n",
    "    nNeigh_ave = coordinations.sum().astype(float)/coordinations.shape[0]\n",
    "    nCon_ave=ncontacts.sum().astype(float)/ncontacts.shape[0]\n",
    "    labels = ['Z','N']\n",
    "    text = [['N_p',p_cen.shape[0]],\n",
    "           ['N_c',contact_cen.shape[0]],\n",
    "           ['A_c',nCon_ave],\n",
    "           ['A_{coor}',nNeigh_ave]]\n",
    "\n",
    "    fig.histogram(hists,bins_num=np.array((12,12)),xlabel='$N$',ylabel='Counts',\n",
    "                  labels=labels,\n",
    "                  directory =folder+'t%01d/c2/particle_middle/'%t )\n",
    "    plt.savefig(folder+'t%01d/c2/particle_middle/N_and_Z.pdf'%t)\n",
    "\n",
    "    # Detect clusters\n",
    "    import scipy.cluster.hierarchy as hac\n",
    "    Cluster = hac.fcluster(hac.linkage(pcen_all[:,:3],'single'),maxdistance,'distance')\n",
    "    print ('number of cluster detected is', Cluster.max())\n",
    "    fig.write_xyz_file_p(folder + 't%01d/c2/particle_middle/Cluster_detection_allParticles'%t,\n",
    "                                    p_cen,Property =Cluster)\n",
    "    # check if the gel is percolating\n",
    "    analysis.percolation(Cluster,imageC2,pcen_all)\n",
    "\n",
    "    #plot cluster size distribution\n",
    "    clusters, counts = np.unique(Cluster, return_counts=True)\n",
    "    cluster_size, cluster_counts = np.unique(counts,return_counts=True)\n",
    "    fig.plot_scatter(clusters,counts,#marker=r'$\\clubsuit$',\n",
    "                                  xlabel='Labelled Clusters',\n",
    "                                  ylabel='Number of Particles',\n",
    "                                  yscale='log')\n",
    "    plt.savefig(folder+'t%01d/c2/particle_middle/cluster_detection_allParticles.pdf'%t)  \n",
    "    \n",
    "    \n",
    "\n",
    "    # which two particles have a common contact point\n",
    "    p1_cen, p2_cen, p_tb_connected, connections, forces = analysis.link_particles(\n",
    "                                dists,contact_cen,contact_size,p_cen)\n",
    "    \n",
    "    coordinations = analysis.coordination(p_cen,maxdistance)\n",
    "    np.savetxt(folder+'t%01d/c2/particle_middle/nNeighbors.txt'%t,coordinations)\n",
    "    \n",
    "    #if a contact is not collinear with two adjacent particles, put three of them collinear\n",
    "    force_vector = analysis.find_force_vector(contact_cen,p1_cen, p2_cen,forces)\n",
    "    np.savetxt(folder+'t%01d/c2/particle_middle/force_vector.txt'%t ,force_vector)\n",
    "\n",
    "    # calculate number of contacts per particle\n",
    "    # sum of force per particle with magnitude or not\n",
    "    ncontacts,local_sum,local_sum_moduli,order,local_f_list,local_f_sum = analysis.n_contacts_pparticle(\n",
    "                                                    p_tb_connected,force_vector,p_cen)\n",
    "    np.savetxt(folder + 't%01d/c2/particle_middle/nContacts.txt'%t,ncontacts)\n",
    "\n",
    "    ##### f direction is contacts to particles, r direction is opposite\n",
    "    stress_tensor, parToCon_list = ca.force_chains3d.compute_stress(p_cen,contact_cen,local_f_list,dists)\n",
    "    major_stress, minor_stress, eigvals,stress_trace,anisotropy = ca.force_chains3d.principal_stress(stress_tensor)\n",
    "\n",
    "    np.savetxt(folder + 't%01d/c2/particle_middle/stress_tensor/minor_stress.txt'%t,np.array(minor_stress).real)\n",
    "    np.savetxt(folder + 't%01d/c2/particle_middle/stress_tensor/major_stress.txt'%t,np.array(major_stress).real)\n",
    "    np.savetxt(folder + 't%01d/c2/particle_middle/stress_tensor/stress_trace.txt'%t,np.array(stress_trace).real)\n",
    "    np.savetxt(folder + 't%01d/c2/particle_middle/stress_tensor/anisotropy.txt'%t,anisotropy)\n",
    "    np.savetxt(folder + 't%01d/c2/particle_middle/stress_tensor/particle_stress_index.txt'%t,p_inbox)\n",
    "    \n",
    "    s = [x[1] for x in stress_tensor]\n",
    "    cPickle.dump(s, open(folder + 't%01d/c2/particle_middle/stress_tensor/stress_tensor.pkl'%t,'wb'))\n",
    "#     np.savetxt(folder + 't%01d/c2/particle_middle/stress_tensor/stress_tensor.txt'%t,np.array(stress_tensor))\n",
    "    \n",
    "    plt.hist(np.real(minor_stress),bins=20,histtype='step')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Minor Stress'),plt.ylabel('pdf')\n",
    "    plt.savefig(folder + 't%01d/c2/particle_middle/stress_tensor/minor_stress_pdf.pdf'%t)\n",
    "    plt.figure()\n",
    "    plt.hist(np.real(major_stress),bins=20,histtype='step')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Major Stress'),plt.ylabel('pdf')\n",
    "    plt.savefig(folder + 't%01d/c2/particle_middle/stress_tensor/major_stress_pdf.pdf'%t)\n",
    "    plt.figure()\n",
    "    plt.hist(stress_trace,bins=20,histtype='step')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Stress Trace'),plt.ylabel('pdf')\n",
    "    plt.savefig(folder + 't%01d/c2/particle_middle/stress_tensor/stress_trace_pdf.pdf'%t)\n",
    "      \n",
    "    np.savetxt(folder + 't0/c2/particle_middle/local_sum_manual.txt',local_sum)\n",
    "\n",
    "    fig.write_xyz_file_p(folder + 't0/c2/particle_middle/particle_forceMagnitude_manual',\n",
    "                                    p_cen[:,:3],Property =local_sum)\n",
    "\n",
    "    fig.write_xyz_file_p(folder + 't0/c2/particle_middle/particle_minor_stress_manual',\n",
    "                                    p_cen[:,:3],Property =minor_stress)\n",
    "\n",
    "    largeForce = local_sum>=local_sum.mean()\n",
    "    fig.write_xyz_file_p(folder + 't0/c2/particle_middle/particle_forceMagnitude_large_manual',\n",
    "                                    p_cen[largeForce][:,:3],Property =local_sum[largeForce])\n",
    "\n",
    "#     major_angle = np.array(major_theta)*360/np.pi\n",
    "#     write_xyz_file(folder + 'c2/particle_middle/particle_major_angle',\n",
    "#                                     p_cen[:,:2],Property =major_angle)\n",
    "#     largeForce = local_sum>=local_sum.mean()\n",
    "#     fig.write_xyz_file(folder + 'c2/particle_middle/particle_major_angle_large',\n",
    "#                                     p_cen[largeForce][:,:2],Property =major_angle[largeForce])\n",
    "    \n",
    "    neighbours_distance, coordinations = ds.coordination(p_cen[:,:3],maxdistance=maxdistance)[:-1]\n",
    "    plt.figure()\n",
    "    plt.hist(ncontacts,bins=12,alpha=0.8,label='$Nz$')\n",
    "    plt.hist(coordinations,bins=12,alpha=0.8,label='$CN$')\n",
    "    plt.xlim(0,15)\n",
    "    plt.legend()\n",
    "    \n",
    "    neighbours_distance=np.array(neighbours_distance)\n",
    "    non_alone = np.where(coordinations>=1)[0]\n",
    "    np.savetxt(folder + 't%01d/c2/particle_middle/non_alone.txt'%t,non_alone)\n",
    "    \n",
    "    highStress_neighbours=[] \n",
    "    for i in non_alone:  \n",
    "        idx = np.where(neighbours_distance[:,0]==i)[0]\n",
    "        newneigh = []\n",
    "        for j in idx:\n",
    "            neighbours = neighbours_distance[j][1]\n",
    "            newneigh.append(neighbours)\n",
    "        highStress_neighbours.append((i,newneigh))\n",
    "\n",
    "    chain_computed = ca.force_chains3d.find_chains(p_cen,\n",
    "                            coordinations,highStress_neighbours,minor_stress,eigvals,threshold=45)\n",
    "    # chain_color, uu, vv,ww,XYZ = ca.force_chains3d.find_chains(p_cen,ncontacts,\n",
    "    #                 highStress_neighbours,minor_stress,eigvals)\n",
    "    chain_color = chain_computed[0]\n",
    "    uu,vv,ww = chain_computed[1],chain_computed[2],chain_computed[3]\n",
    "    XYZ,pairs,Neigh = chain_computed[-3],chain_computed[-2],chain_computed[-1]\n",
    "\n",
    "    chainlength,labelled_chain,coloredP,length = ca.force_chains3d.color_chains(\n",
    "                                            chain_color,p_cen,non_alone)\n",
    "    NP_inChain = length[length>2].shape[0]\n",
    "    \n",
    "    to_delete = []\n",
    "    for i in range(len(pairs)):\n",
    "        for j in range(i+1,len(pairs)):\n",
    "            if pairs[i] == pairs[j][::-1]:\n",
    "                to_delete.append(j)\n",
    "\n",
    "    new_pairs = np.delete(pairs,to_delete,axis=0)\n",
    "    long_pairs =[]\n",
    "    for i in range(len(new_pairs)):\n",
    "        Lchain = length[new_pairs[i][0]]\n",
    "        if Lchain >3:\n",
    "            long_pairs.append((new_pairs[i][0],new_pairs[i][1],Lchain))\n",
    "\n",
    "    pair_index = []\n",
    "    for i in range(len(long_pairs)):\n",
    "        p1 = new_pairs[i][0]\n",
    "        p2 = new_pairs[i][1]\n",
    "        old_p1 = non_alone[p1]\n",
    "        old_p2 = non_alone[p2]\n",
    "        c_idx =np.where(p_tb_connected[:,1]==old_p1)[0]\n",
    "        if p_tb_connected[c_idx].shape[0]>0:\n",
    "            connect_p = p_tb_connected[c_idx]\n",
    "            matched = [p==old_p2 for p in connect_p[:,-1]]\n",
    "            if any(matched):\n",
    "                size = connect_p[matched][0][0]\n",
    "                pair_index.append((p1,p2,size))\n",
    "    pair_index = np.array(pair_index)\n",
    "\n",
    "    pair_index_oldp = []\n",
    "    for i in range(len(long_pairs)):\n",
    "        p1 = long_pairs[i][0]\n",
    "        p2 = long_pairs[i][1]\n",
    "        old_p1 = non_alone[p1]\n",
    "        old_p2 = non_alone[p2]\n",
    "\n",
    "        pair_index_oldp.append((old_p1,old_p2))\n",
    "    pair_index_oldp = np.array(pair_index_oldp)\n",
    "\n",
    "    np.savetxt(folder+'t%01d/c2/particle_middle/test/p_non_alone.txt'%t,p_cen[non_alone])\n",
    "    np.savetxt(folder+'t%01d/c2/particle_middle/test/labelled_chain.txt'%t,labelled_chain)\n",
    "    np.savetxt(folder+'t%01d/c2/particle_middle/test/new_pairs.txt'%t,new_pairs)\n",
    "    np.savetxt(folder+'t%01d/c2/particle_middle/test/pair_index.txt'%t,pair_index)\n",
    "\n",
    "    np.savetxt(folder+'TCC/chainlength/chainlength_t%02d.txt'%t,length)\n",
    "    plt.hist(length,bins=10,normed=True)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('chain size [particles]'),plt.ylabel('pdf')\n",
    "    plt.savefig(folder+'t%01d/chainlength_distribution.pdf'%t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
